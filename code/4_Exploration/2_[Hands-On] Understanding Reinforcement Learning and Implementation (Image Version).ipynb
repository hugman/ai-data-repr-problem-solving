{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c43866b5-cb4c-4a00-bfaf-7904857f3c33",
      "metadata": {
        "id": "c43866b5-cb4c-4a00-bfaf-7904857f3c33"
      },
      "source": [
        "# [Hands-On] Understanding Reinforcement Learning and Implementation (Image Version)\n",
        "\n",
        "- Author : Sangkeun Jung (hugmanskj@gmail.com)\n",
        "\n",
        "> Educational Purpose"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92ecfb3-a869-4692-bdf4-e6a6b2bfdbd8",
      "metadata": {
        "id": "f92ecfb3-a869-4692-bdf4-e6a6b2bfdbd8"
      },
      "source": [
        "This tutorial illustrates how to train a Deep Q-Network (DQN) on image inputs from the CartPole environment.\n",
        "Key points include:\n",
        "\n",
        "- Handling image inputs via ResNet-18 (pretrained)\n",
        "- Preprocessing and normalizing RGB frames\n",
        "- Implementing a replay buffer and training loop\n",
        "- Visualizing intermediate states as images and text, then compiling them into a GIF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d7a3b5-5838-4422-8647-7cb06b953f89",
      "metadata": {
        "id": "48d7a3b5-5838-4422-8647-7cb06b953f89"
      },
      "source": [
        "# Overview\n",
        "- Traditional CartPole uses a 4D numeric state: cartposition,cartvelocity,poleangle,poleangularvelocity.\n",
        "- In this image-based version, we rely on the environment’s raw rendered frames (rgb_array) as inputs.\n",
        "- A ResNet-18 model (pretrained on ImageNet) is used to extract a 128-dimensional embedding from each frame.\n",
        "- A fully connected layer then outputs the Q-values for each action (left/right) based on the extracted features.\n",
        "- This approach generalizes to higher-dimensional visual inputs in reinforcement learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7927056-cdb2-4646-b719-ee0b38efdb94",
      "metadata": {
        "id": "e7927056-cdb2-4646-b719-ee0b38efdb94"
      },
      "source": [
        "## CartPole\n",
        "- Actions: Move the cart either left (0) or right (1).\n",
        "- Goal: Prevent the pole from falling over by controlling the cart’s movements.\n",
        "- Reward: +1 at every timestep the pole remains upright.\n",
        "- Episode ends when the pole tilts too far or the cart exits the track bounds.\n",
        "\n",
        "By switching from numeric states to image states, we practice using CNNs (e.g., ResNet) to handle high-dimensional inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747a76ba-0c17-48ee-8dec-d4fedaf531ec",
      "metadata": {
        "id": "747a76ba-0c17-48ee-8dec-d4fedaf531ec"
      },
      "source": [
        "# What We'll Build\n",
        "1. Image Preprocessing:\n",
        "    - Resize the raw RGB frames to (224×224) and normalize to match ImageNet standards.\n",
        "2. Neural Network:\n",
        "    - ResNet-18 (pretrained) as an encoder → 128-d embedding\n",
        "    - Q-Head: Outputs Q-values for each action\n",
        "3. Replay Buffer: Stores transitions for mini-batch sampling\n",
        "4. DQN Training Loop: Epsilon-greedy exploration, Q-target, MSE loss, target network updates, etc.\n",
        "5. Visualization:\n",
        "    - Save rendered frames and text info for each timestep\n",
        "    - Overlay text onto images and create a GIF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea4c7ab-a7de-4860-a8e3-c0ed1973b04c",
      "metadata": {
        "id": "2ea4c7ab-a7de-4860-a8e3-c0ed1973b04c"
      },
      "source": [
        "# Environment Setup\n",
        "Install the required packages (if not already installed):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cdb3fd-595f-42f0-8294-8c2c4ce6bb58",
      "metadata": {
        "id": "a0cdb3fd-595f-42f0-8294-8c2c4ce6bb58",
        "outputId": "5d53fde5-2505-427a-9cbc-2210ad24f3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (0.26.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: torch in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (2.6.0+cu126)\n",
            "Requirement already satisfied: torchvision in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (0.21.0+cu126)\n",
            "Requirement already satisfied: transformers in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (4.48.3)\n",
            "Requirement already satisfied: pillow in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (11.0.0)\n",
            "Requirement already satisfied: imageio in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (2.37.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: filelock in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hugman\\anaconda3\\envs\\book_ai\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym numpy torch torchvision transformers pillow imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a080c4-8b6e-4974-95e9-229724e64112",
      "metadata": {
        "id": "81a080c4-8b6e-4974-95e9-229724e64112"
      },
      "source": [
        "# Required Libraries\n",
        "Let's import all necessary libraries for our implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5791f007-0f6f-4af5-9f06-85e8c4912589",
      "metadata": {
        "id": "5791f007-0f6f-4af5-9f06-85e8c4912589"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import imageio\n",
        "\n",
        "from torchvision import models, transforms\n",
        "from collections import deque\n",
        "from PIL import ImageDraw, ImageFont\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0afa74-c692-41fe-a5eb-7a17c708b48d",
      "metadata": {
        "id": "2a0afa74-c692-41fe-a5eb-7a17c708b48d"
      },
      "source": [
        "## Key libraries we're using:\n",
        "\n",
        "- gymnasium: For the CartPole environment\n",
        "- torch: For neural network implementation\n",
        "- imageio: For creating visual outputs\n",
        "- matplotlib: For plotting results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "789ae4e3-d52e-4b77-99ce-8147a52dc195",
      "metadata": {
        "id": "789ae4e3-d52e-4b77-99ce-8147a52dc195"
      },
      "source": [
        "# Neural Network Architecture\n",
        "## Image Encoder (ResNet-18)\n",
        "- Pretrained on ImageNet, so it can handle generic natural images.\n",
        "- feature_extractor: All layers of ResNet-18 minus the final classification FC.\n",
        "- fc: Outputs a 128-d embedding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c100a984-9e5f-4ee2-828b-0da9f7d75288",
      "metadata": {
        "id": "c100a984-9e5f-4ee2-828b-0da9f7d75288"
      },
      "outputs": [],
      "source": [
        "class ResNetEncoder(nn.Module):\n",
        "   \"\"\"\n",
        "   Image Encoder using ResNet-18.\n",
        "   Takes CartPole's raw image (210x160x3) as input and generates a 128-dimensional feature vector.\n",
        "   \"\"\"\n",
        "   def __init__(self, embed_dim=128):\n",
        "       super(ResNetEncoder, self).__init__()\n",
        "       resnet = models.resnet18(pretrained=True)\n",
        "       self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Remove last FC layer\n",
        "       self.fc = nn.Linear(resnet.fc.in_features, embed_dim)  # Transform to 128 dimensions\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.feature_extractor(x)  # Extract ResNet features\n",
        "       x = x.view(x.size(0), -1)  # Flatten\n",
        "       x = self.fc(x)  # Transform to 128 dimensions\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27896c25-5756-4ef3-9359-7f19184b0412",
      "metadata": {
        "id": "27896c25-5756-4ef3-9359-7f19184b0412"
      },
      "source": [
        "## DQN Network\n",
        "Our complete DQN combines the encoder with a policy head:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8649552-c81f-48c9-bf74-b00ced76714b",
      "metadata": {
        "id": "a8649552-c81f-48c9-bf74-b00ced76714b"
      },
      "source": [
        "## PolicyNetwork (DQN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5971d76b-0670-4246-8317-d4b012066cbf",
      "metadata": {
        "id": "5971d76b-0670-4246-8317-d4b012066cbf"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "   \"\"\"\n",
        "   ResNet-based Image Encoder + Q-Network.\n",
        "   \"\"\"\n",
        "   def __init__(self, action_dim, embed_dim=128):\n",
        "       super(DQN, self).__init__()\n",
        "       self.encoder = ResNetEncoder(embed_dim)  # Feature Extraction using ResNet\n",
        "       self.q_head = nn.Linear(embed_dim, action_dim)  # Output action Q-values with FC Layer\n",
        "\n",
        "   def forward(self, x):\n",
        "       emb = self.encoder(x)\n",
        "       q = self.q_head(emb)\n",
        "       return q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6833df-247f-4704-a6a5-cc8df608a800",
      "metadata": {
        "id": "ed6833df-247f-4704-a6a5-cc8df608a800"
      },
      "source": [
        "forward: Takes the image, extracts features with ResNetEncoder, then outputs Q-values for each action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb839f79-5a33-4d2b-9023-188f8799530c",
      "metadata": {
        "id": "fb839f79-5a33-4d2b-9023-188f8799530c"
      },
      "source": [
        "# Image Preprocessing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4dbd089-7552-46ee-b8bb-af279c49d7a5",
      "metadata": {
        "id": "c4dbd089-7552-46ee-b8bb-af279c49d7a5"
      },
      "source": [
        "- ResNet expects input based on ImageNet standards (224x224, Normalized values)\n",
        "- gym's CartPole provides raw images of size (210, 160, 3)\n",
        "- Convert these to size (224, 224) and apply Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec9dd6c8-d3eb-4e19-b069-15e59c4af829",
      "metadata": {
        "id": "ec9dd6c8-d3eb-4e19-b069-15e59c4af829"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "   transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
        "   transforms.ToTensor(),  # Convert (H, W, C) → (C, H, W)\n",
        "   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet stats\n",
        "])\n",
        "\n",
        "def preprocess_image(frame):\n",
        "   \"\"\"\n",
        "   Convert CartPole image (np.array) to Tensor\n",
        "   \"\"\"\n",
        "   img = Image.fromarray(frame)  # Convert numpy array to PIL Image\n",
        "   img = transform(img)  # Apply transforms\n",
        "   return img.unsqueeze(0)  # (C, H, W) → (1, C, H, W) (add batch dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89fd77da-ef9c-4fec-b408-e72c3bf691dd",
      "metadata": {
        "id": "89fd77da-ef9c-4fec-b408-e72c3bf691dd"
      },
      "source": [
        "# Replay Buffer\n",
        "The replay buffer is crucial for stable learning in DQN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e68189d-19ff-4925-bcfb-3e2d6c36eb6a",
      "metadata": {
        "id": "5e68189d-19ff-4925-bcfb-3e2d6c36eb6a"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=10000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "        states, actions, rewards, next_states, dones = zip(*[self.buffer[idx] for idx in batch])\n",
        "\n",
        "        return (\n",
        "            torch.stack(states).squeeze(1),  # (batch, 1, C, H, W) → (batch, C, H, W)\n",
        "            actions,\n",
        "            rewards,\n",
        "            torch.stack(next_states).squeeze(1),  # (batch, 1, C, H, W) → (batch, C, H, W)\n",
        "            dones\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24674b0e-b1c7-4904-a423-a259dbf622e3",
      "metadata": {
        "id": "24674b0e-b1c7-4904-a423-a259dbf622e3"
      },
      "source": [
        "- push: Stores a single transition ((state, action, reward, next_state, done)).\n",
        "- sample: Returns a random minibatch of transitions.\n",
        "- We use .stack() to combine individual image tensors into a batch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5b7353-3a82-4e15-aaaf-d3d9d7150a65",
      "metadata": {
        "id": "cc5b7353-3a82-4e15-aaaf-d3d9d7150a65"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0314cc68-2804-4e13-aef2-5c734da59e6d",
      "metadata": {
        "id": "0314cc68-2804-4e13-aef2-5c734da59e6d"
      },
      "source": [
        "### store_frames_and_info function\n",
        "This function stores raw images and step-by-step textual info (e.g., cart position, pole angle) into a folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f8de4e-1416-4ae7-9044-014cf21662d0",
      "metadata": {
        "id": "f4f8de4e-1416-4ae7-9044-014cf21662d0"
      },
      "outputs": [],
      "source": [
        "def store_frames_and_info(episode_number, frames, info_texts, render_path):\n",
        "   \"\"\"\n",
        "   Args:\n",
        "       episode_number (int): Episode number\n",
        "       frames (list of np.array): Array of rendered images\n",
        "       info_texts (list of str): Information strings for each step\n",
        "       render_path (str): Parent directory path for saving\n",
        "   \"\"\"\n",
        "   ep_folder = os.path.join(render_path, f\"episode_{episode_number}\")\n",
        "   os.makedirs(ep_folder, exist_ok=True)\n",
        "\n",
        "   for i, (img, info_str) in enumerate(zip(frames, info_texts)):\n",
        "       # step_xxx.png\n",
        "       png_path = os.path.join(ep_folder, f\"step_{i:03d}.png\")\n",
        "       imageio.imwrite(png_path, img)\n",
        "\n",
        "       # step_xxx.info.txt\n",
        "       info_path = os.path.join(ep_folder, f\"step_{i:03d}.info.txt\")\n",
        "       with open(info_path, \"w\", encoding=\"utf-8\") as f:\n",
        "           f.write(info_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7238c3-fb92-457a-950b-57d5f89deb8d",
      "metadata": {
        "id": "6c7238c3-fb92-457a-950b-57d5f89deb8d"
      },
      "source": [
        "Below is the main training function. Key steps:\n",
        "\n",
        "- Initialize environment with render_mode=\"rgb_array\".\n",
        "- Epsilon-greedy action selection.\n",
        "- Replay Buffer: Store transitions.\n",
        "- Minibatch Training: Sample from buffer, compute Q-values, update DQN.\n",
        "- Target Network: Updated periodically.\n",
        "- Logging & Visualization: Optionally save each step’s frame + text info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f56f881-30ff-4853-b421-4593958e6d86",
      "metadata": {
        "id": "7f56f881-30ff-4853-b421-4593958e6d86"
      },
      "outputs": [],
      "source": [
        "def train_dqn(\n",
        "   env_name=\"CartPole-v1\",\n",
        "   num_episodes=100,\n",
        "   batch_size=32,\n",
        "   gamma=0.99,\n",
        "   lr=1e-3,\n",
        "   epsilon_start=1.0,\n",
        "   epsilon_end=0.01,\n",
        "   epsilon_decay=500,\n",
        "   target_update_interval=20,\n",
        "   buffer_capacity=50000,\n",
        "   save_render=True,\n",
        "   render_path=\"./cartpole_frames\"\n",
        "):\n",
        "   env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "   action_dim = env.action_space.n\n",
        "   dqn = DQN(action_dim)\n",
        "   target_dqn = DQN(action_dim)\n",
        "   target_dqn.load_state_dict(dqn.state_dict())\n",
        "   optimizer = optim.Adam(dqn.parameters(), lr=lr)\n",
        "   replay_buffer = ReplayBuffer(capacity=buffer_capacity)\n",
        "   epsilon = epsilon_start\n",
        "   epsilon_decay_rate = (epsilon_start - epsilon_end) / epsilon_decay\n",
        "   total_rewards_list = []\n",
        "\n",
        "   for episode in range(num_episodes):\n",
        "       obs, _ = env.reset()\n",
        "       img_tensor = preprocess_image(env.render())\n",
        "       done = False\n",
        "       episode_reward = 0\n",
        "       episode_frames = []\n",
        "       episode_info_texts = []\n",
        "       step_count = 0\n",
        "\n",
        "       while not done:\n",
        "           # Epsilon-greedy action selection\n",
        "           if np.random.rand() < epsilon:\n",
        "               action = env.action_space.sample()\n",
        "           else:\n",
        "               with torch.no_grad():\n",
        "                   q_values = dqn(img_tensor)\n",
        "                   action = q_values.argmax(dim=1).item()\n",
        "\n",
        "           next_obs, reward, done, truncated, _ = env.step(action)\n",
        "           done = done or truncated\n",
        "           next_img_tensor = preprocess_image(env.render())\n",
        "           replay_buffer.push(img_tensor, action, reward, next_img_tensor, done)\n",
        "           episode_reward += reward\n",
        "           img_tensor = next_img_tensor\n",
        "\n",
        "           # ==== Collect rendering and info ====\n",
        "           if save_render:\n",
        "               frame = env.render()  # (H, W, 3) numpy\n",
        "               episode_frames.append(frame)\n",
        "               # CartPole state (obs[0] = pos, obs[1] = vel, obs[2] = angle, obs[3] = angular vel)\n",
        "               info_str = (\n",
        "                   f\"Episode={episode+1}, Step={step_count}\\n\"\n",
        "                   f\"Cart Position={next_obs[0]:.3f}, Cart Velocity={next_obs[1]:.3f}\\n\"\n",
        "                   f\"Pole Angle={next_obs[2]:.3f}, Pole Angular Vel={next_obs[3]:.3f}\\n\"\n",
        "                   f\"Action={action}, Reward={reward:.2f}\\n\"\n",
        "               )\n",
        "               episode_info_texts.append(info_str)\n",
        "           # ============================\n",
        "\n",
        "           step_count += 1\n",
        "\n",
        "           # Training\n",
        "           if len(replay_buffer) > batch_size:\n",
        "               states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
        "               actions_t = torch.LongTensor(actions).unsqueeze(1)\n",
        "               rewards_t = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "               dones_t = torch.BoolTensor(dones).unsqueeze(1)\n",
        "\n",
        "               q_pred = dqn(states).gather(1, actions_t)\n",
        "               with torch.no_grad():\n",
        "                   q_next = target_dqn(next_states).max(dim=1, keepdim=True)[0]\n",
        "                   q_target = rewards_t + gamma * q_next * (~dones_t)\n",
        "\n",
        "               loss = F.mse_loss(q_pred, q_target)\n",
        "               optimizer.zero_grad()\n",
        "               loss.backward()\n",
        "               optimizer.step()\n",
        "\n",
        "               if epsilon > epsilon_end:\n",
        "                   epsilon -= epsilon_decay_rate\n",
        "\n",
        "       total_rewards_list.append(episode_reward)\n",
        "\n",
        "       if (episode + 1) % target_update_interval == 0:\n",
        "           target_dqn.load_state_dict(dqn.state_dict())\n",
        "\n",
        "       if (episode + 1) % 10 == 0:\n",
        "           print(f\"[Episode {episode+1}] Reward: {episode_reward}, Epsilon={epsilon:.3f}\")\n",
        "           # Save frames & info\n",
        "           store_frames_and_info(\n",
        "               episode_number=episode+1,\n",
        "               frames=episode_frames,\n",
        "               info_texts=episode_info_texts,\n",
        "               render_path=render_path\n",
        "           )\n",
        "\n",
        "   env.close()\n",
        "   return dqn, total_rewards_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99156650-0405-4072-8bb1-93dd549298fd",
      "metadata": {
        "id": "99156650-0405-4072-8bb1-93dd549298fd"
      },
      "source": [
        "# Visualization Tools\n",
        "We've implemented comprehensive visualization tools:\n",
        "\n",
        "- Frame capture during training\n",
        "- State information overlay\n",
        "- GIF creation for episode replay\n",
        "\n",
        "During each episode, we can save frames and text info to see what happens in each step (such as cart position, pole angle, and chosen action).  \n",
        "We also provide functions to overlay this info onto images and create GIFs, making it easy to visualize the agent’s performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a815d4-cb55-42bf-a4a8-03685b642463",
      "metadata": {
        "id": "24a815d4-cb55-42bf-a4a8-03685b642463"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "def overlay_text_on_image(image_path, info_path, font_path=None):\n",
        "   \"\"\"\n",
        "   image_path: Path to PNG file\n",
        "   info_path: Path to corresponding .info.txt file\n",
        "   font_path: Path to TTF font (optional)\n",
        "   return: Pillow Image object (image with overlaid text)\n",
        "   \"\"\"\n",
        "   img = Image.open(image_path).convert(\"RGB\")\n",
        "   draw = ImageDraw.Draw(img)\n",
        "\n",
        "   # Font setup (use default if not provided)\n",
        "   if font_path is not None:\n",
        "       font = ImageFont.truetype(font_path, size=18)\n",
        "   else:\n",
        "       font = ImageFont.load_default()\n",
        "\n",
        "   text = \"\"\n",
        "   if os.path.exists(info_path):\n",
        "       with open(info_path, \"r\", encoding=\"utf-8\") as f:\n",
        "           text = f.read()\n",
        "\n",
        "   # Display multi-line text with line breaks\n",
        "   lines = text.strip().split(\"\\n\")\n",
        "\n",
        "   # Position setup\n",
        "   x, y = 10, 10\n",
        "   padding = 5  # Padding for black box\n",
        "   max_width = max([draw.textlength(line, font=font) for line in lines]) + 2 * padding\n",
        "   box_height = len(lines) * 20 + 2 * padding  # Adjust box size based on number of lines\n",
        "\n",
        "   # Semi-transparent black box (improves readability)\n",
        "   draw.rectangle([(x - padding, y - padding), (x + max_width, y + box_height)], fill=(0, 0, 0, 150))\n",
        "\n",
        "   # Add text (yellow)\n",
        "   for line in lines:\n",
        "       draw.text((x, y), line, fill=(255, 255, 0), font=font)\n",
        "       y += 20  # Line spacing\n",
        "\n",
        "   return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c562df9-e04c-4034-8480-3523b1fb36a9",
      "metadata": {
        "id": "3c562df9-e04c-4034-8480-3523b1fb36a9"
      },
      "outputs": [],
      "source": [
        "def make_gif_with_overlay(ep_folder, output_gif=\"cartpole_overlay.gif\", fps=30, font_path=None):\n",
        "   \"\"\"\n",
        "   ep_folder: Path to 'episode_N' directory (containing PNG & info.txt files)\n",
        "   output_gif: Path for output GIF file to be created\n",
        "   font_path: Path to TTF font (uses default font if not provided)\n",
        "   \"\"\"\n",
        "   # Sort PNG files (step_000.png, step_001.png ...)\n",
        "   file_list = sorted([f for f in os.listdir(ep_folder) if f.endswith(\".png\")])\n",
        "   frames = []\n",
        "\n",
        "   for file_name in file_list:\n",
        "       image_path = os.path.join(ep_folder, file_name)\n",
        "       info_path = image_path.replace(\".png\", \".info.txt\")\n",
        "       # Create image with text overlay\n",
        "       annotated_img = overlay_text_on_image(image_path, info_path, font_path=font_path)\n",
        "       frames.append(np.array(annotated_img))  # Convert to numpy array\n",
        "\n",
        "   if len(frames) > 0:\n",
        "       imageio.mimsave(output_gif, frames, fps=fps)\n",
        "       print(f\"GIF saved: {output_gif}\")\n",
        "   else:\n",
        "       print(f\"No PNG files found in {ep_folder}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ebd298-9268-414a-9a03-4054ce4c4f70",
      "metadata": {
        "id": "36ebd298-9268-414a-9a03-4054ce4c4f70"
      },
      "source": [
        "#### Running the Training\n",
        "To train your agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0751233-5625-4f06-b323-12a7321558d4",
      "metadata": {
        "id": "b0751233-5625-4f06-b323-12a7321558d4",
        "outputId": "be4e9327-2abd-4e56-f21b-567452e67599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Episode 10] Reward: 23.0, Epsilon=0.568\n",
            "[Episode 20] Reward: 11.0, Epsilon=0.212\n",
            "[Episode 30] Reward: 47.0, Epsilon=0.008\n",
            "[Episode 40] Reward: 14.0, Epsilon=0.008\n",
            "[Episode 50] Reward: 33.0, Epsilon=0.008\n",
            "[Episode 60] Reward: 11.0, Epsilon=0.008\n",
            "[Episode 70] Reward: 32.0, Epsilon=0.008\n",
            "[Episode 80] Reward: 9.0, Epsilon=0.008\n",
            "[Episode 90] Reward: 16.0, Epsilon=0.008\n",
            "[Episode 100] Reward: 10.0, Epsilon=0.008\n",
            "[Episode 110] Reward: 13.0, Epsilon=0.008\n",
            "[Episode 120] Reward: 33.0, Epsilon=0.008\n",
            "[Episode 130] Reward: 22.0, Epsilon=0.008\n",
            "[Episode 140] Reward: 26.0, Epsilon=0.008\n",
            "[Episode 150] Reward: 19.0, Epsilon=0.008\n",
            "[Episode 160] Reward: 9.0, Epsilon=0.008\n",
            "[Episode 170] Reward: 10.0, Epsilon=0.008\n",
            "[Episode 180] Reward: 8.0, Epsilon=0.008\n",
            "[Episode 190] Reward: 22.0, Epsilon=0.008\n",
            "[Episode 200] Reward: 15.0, Epsilon=0.008\n",
            "[Episode 210] Reward: 11.0, Epsilon=0.008\n",
            "[Episode 220] Reward: 23.0, Epsilon=0.008\n",
            "[Episode 230] Reward: 8.0, Epsilon=0.008\n",
            "[Episode 240] Reward: 16.0, Epsilon=0.008\n",
            "[Episode 250] Reward: 9.0, Epsilon=0.008\n",
            "[Episode 260] Reward: 9.0, Epsilon=0.008\n",
            "[Episode 270] Reward: 40.0, Epsilon=0.008\n",
            "[Episode 280] Reward: 8.0, Epsilon=0.008\n",
            "[Episode 290] Reward: 11.0, Epsilon=0.008\n",
            "[Episode 300] Reward: 13.0, Epsilon=0.008\n"
          ]
        }
      ],
      "source": [
        "dqn_model, rewards = train_dqn(\n",
        "    env_name=\"CartPole-v1\",\n",
        "    num_episodes=500,\n",
        "    save_render=True,\n",
        "    render_path=\"./cartpole_frames\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4baa24b9-3ea9-4727-b1c7-d10bcd665258",
      "metadata": {
        "id": "4baa24b9-3ea9-4727-b1c7-d10bcd665258",
        "outputId": "263a00c1-6ddb-47b0-c71f-c77f1ea78d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GIF saved: cartpole_ep300.gif\n"
          ]
        }
      ],
      "source": [
        "ep_folder = \"./cartpole_frames/episode_500\"\n",
        "make_gif_with_overlay(ep_folder, output_gif=\"cartpole_ep500.gif\", fps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1341885-95b2-4933-9748-c6d4b85d4914",
      "metadata": {
        "id": "d1341885-95b2-4933-9748-c6d4b85d4914",
        "outputId": "6735a601-5cab-4d3f-a0c0-14aca4081925"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'IPyImage' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 저장된 GIF 파일을 Jupyter Notebook에서 출력\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m IPyImage(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcartpole_ep300.gif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'IPyImage' is not defined"
          ]
        }
      ],
      "source": [
        "IPyImage(filename=\"cartpole_ep500.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628cfe31-0a00-4fb0-94c7-c45ebcefcf4a",
      "metadata": {
        "id": "628cfe31-0a00-4fb0-94c7-c45ebcefcf4a"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this tutorial, we implemented a Deep Q-Network (DQN) to handle image inputs in the CartPole environment:\n",
        "\n",
        "- We used ResNet-18 (pretrained on ImageNet) to encode raw RGB frames into a 128-d feature vector.\n",
        "- The resulting features were fed into a fully connected layer to produce the Q-values for the two actions.\n",
        "- Despite its simplicity, this approach showcases how to apply RL algorithms to high-dimensional visual inputs.\n",
        "\n",
        "## Key Takeaways\n",
        "1. Image-Based RL:\n",
        "    - More computationally expensive than using low-dimensional numeric states.\n",
        "    - Demonstrates the generalization to real-world visual scenarios (e.g., robotics, Atari games, self-driving).\n",
        "2. Replay Buffer:\n",
        "    - Essential for stable DQN training.\n",
        "    - Decouples data collection from network updates.\n",
        "3. Target Network:\n",
        "    - Helps stabilize Q-learning by reducing moving-target issues.\n",
        "    - Update it periodically (e.g., every 20 episodes).\n",
        "4. Advanced Techniques (future exploration):\n",
        "    - Frame Stacking (e.g., 4 consecutive frames) to better capture dynamic information.\n",
        "    - Fine-Tuning the ResNet backbone vs. keeping it frozen.\n",
        "    - Larger batch sizes, more episodes, or different CNN architectures."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "book_ai",
      "language": "python",
      "name": "book_ai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}